# Default configuration for stroke classification

# Data settings
data:
  data_dir: ./data/processed
  image_size: 224
  batch_size: 32
  num_workers: 4
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15

# Model settings
model:
  architecture: resnet50  # Options: simple_cnn, resnet18, resnet34, resnet50, resnet101, efficientnet_b0, etc.
  pretrained: true
  freeze_backbone: false
  in_channels: 3
  num_classes: 2

# Training settings
training:
  num_epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: adam  # Options: adam, adamw, sgd
  scheduler: step  # Options: step, cosine, plateau
  scheduler_params:
    step_size: 30
    gamma: 0.1
  early_stopping_patience: 15
  gradient_clip: 1.0

# Loss function
loss:
  type: cross_entropy  # Options: cross_entropy, weighted_cross_entropy, focal
  class_weights: null  # Set to [w0, w1] for weighted loss

# Augmentation
augmentation:
  train:
    horizontal_flip: 0.5
    vertical_flip: 0.5
    rotation_limit: 30
    brightness_contrast: 0.5
    gaussian_noise: 0.3
    gaussian_blur: 0.3
  test:
    horizontal_flip: 0.0  # No augmentation during test

# Evaluation
evaluation:
  patient_level_aggregation: mean  # Options: mean, max, majority
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
    - sensitivity
    - specificity

# Experiment tracking
experiment:
  name: baseline_experiment
  base_dir: ./experiments
  save_frequency: 10  # Save checkpoint every N epochs
  log_frequency: 10  # Log metrics every N batches

# Reproducibility
seed: 42

# Paths
paths:
  checkpoint_dir: ./experiments/checkpoints
  log_dir: ./experiments/logs
  result_dir: ./experiments/results
